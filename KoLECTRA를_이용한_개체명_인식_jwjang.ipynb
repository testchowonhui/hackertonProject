{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIVaKfblwq13"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import ElectraModel, ElectraTokenizer\n",
        "\n",
        "# KoELECTRA-Base\n",
        "model = ElectraModel.from_pretrained(\"monologg/koelectra-base-discriminator\")\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n",
        "\n",
        "# KoELECTRA-Small\n",
        "model = ElectraModel.from_pretrained(\"monologg/koelectra-small-discriminator\")\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-small-discriminator\")"
      ],
      "metadata": {
        "id": "ujwiAfU11A9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Leo97/KoELECTRA-small-v3-modu-ner\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"Leo97/KoELECTRA-small-v3-modu-ner\")\n",
        "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "example = \"서울역으로 안내해줘.\"\n",
        "ner_results = ner(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "dc482Yvs1dY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0. CPU 및 GPU 환경 설정\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "# 이걸 왜 하는거임 ?\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jWJBfJhbKG4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "DSzo3Y-_KqCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 한국해양대학교 자연어처리 연구실 NER 데이터셋"
      ],
      "metadata": {
        "id": "LGLU3OQqLA1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kmounlp/NER.git"
      ],
      "metadata": {
        "id": "ONiWAUKZLFCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "WIcOCgd7LNOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = []"
      ],
      "metadata": {
        "id": "lzr99SibLTxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in os.walk('NER/'):\n",
        "    for y in glob.glob(os.path.join(x[0], '*_NER.txt')):\n",
        "        file_list.append(y)"
      ],
      "metadata": {
        "id": "4hw8t_2QLWUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = sorted(file_list)"
      ],
      "metadata": {
        "id": "3ujmP7IGbv9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in file_list:\n",
        "    print(file_path)"
      ],
      "metadata": {
        "id": "ys8zWCANbzos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국 해양대학교 데이터셋\n",
        "from pathlib import Path\n",
        "\n",
        "file_path = file_list[0]\n",
        "file_path = Path(file_path)\n",
        "raw_text = file_path.read_text().strip()"
      ],
      "metadata": {
        "id": "-OAMTmvHbXVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_text[0:1000])"
      ],
      "metadata": {
        "id": "N_ZjORHLcDct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NAVER NLP Challenge 2018 NER 데이터셋\n"
      ],
      "metadata": {
        "id": "ZLqU4hHGcOHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install korpora"
      ],
      "metadata": {
        "id": "H7rZt9IycHtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import Korpora\n",
        "corpus = Korpora.load(\"naver_changwon_ner\")"
      ],
      "metadata": {
        "id": "5FDuk059cWXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd 'drive/MyDrive/공적말하기_프로젝트/02. 프로젝트 실행/jwjang_workspace/태그인식 테스트/dataset_koelectra'\n",
        "# /MyDrive/공적말하기_프로젝트/02. 프로젝트 실행/jwjang_workspace/태그인식 테스트/dataset_koelectra\n",
        "!ls"
      ],
      "metadata": {
        "id": "P_PugsqznEwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "org = pd.read_csv('상장법인목록.csv',)\n",
        "org_df = org.iloc[:, 0:1]"
      ],
      "metadata": {
        "id": "1-98NecxcptX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 네이버 데이터셋 전처리"
      ],
      "metadata": {
        "id": "avVv0fiyrPS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naver_read_file(file_list):\n",
        "\n",
        "  token_docs = []\n",
        "  tag_docs = []\n",
        "\n",
        "  for doc in file_list:\n",
        "    tokens = []\n",
        "    tags = []\n",
        "    list1=doc.words\n",
        "    list2=doc.tags\n",
        "\n",
        "    for text, docs in zip(list1, list2):\n",
        "      try:\n",
        "        tag = docs\n",
        "        if tag == 'ORG-B':\n",
        "          tag='B-ORG'\n",
        "\n",
        "        # 2: pos, 3: ner\n",
        "          if tag in 'B-ORG':\n",
        "            token = random.sample(org_df['회사명'].tolist(), k=1)[0] # tag가 B-ORG이면 상장법인목록의 회사명 중 하나로 랜덤으로\n",
        "          else:\n",
        "            token = text\n",
        "        else:\n",
        "          token = text\n",
        "          tag = 'O'\n",
        "        for i, syllable in enumerate(token): # 음절 단위로 자르고\n",
        "          tokens.append(syllable)\n",
        "          modi_tag = tag\n",
        "          if i > 0:\n",
        "            if tag[0] == 'B':\n",
        "              modi_tag = 'I' + tag[1:] # BIO tag를 부착\n",
        "          tags.append(modi_tag)\n",
        "      except:\n",
        "        continue\n",
        "    token_docs.append(tokens)\n",
        "    tag_docs.append(tags)\n",
        "\n",
        "  return token_docs, tag_docs\n"
      ],
      "metadata": {
        "id": "YutX6ysbrR1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naver_text, naver_tags = naver_read_file(corpus.train)"
      ],
      "metadata": {
        "id": "VugoceYHuaxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(naver_text))\n",
        "print(len(naver_tags))"
      ],
      "metadata": {
        "id": "PoAAJUKYuhD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(naver_text[0], end='\\n\\n') # 음절 단위로 잘 잘림\n",
        "print(naver_tags[0])"
      ],
      "metadata": {
        "id": "kyJZv58Fug5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def read_file(file_list):\n",
        "  token_docs = []\n",
        "  tag_docs = []\n",
        "  for file_path in file_list:\n",
        "    # print('read file from ', file_path)\n",
        "    file_path = Path(file_path)\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    for doc in raw_docs:\n",
        "      tokens = []\n",
        "      tags = []\n",
        "      for line in doc.split('\\n'):\n",
        "        if line[0:1] == \"$\" or line[0:1] == \";\" or line[0:2] == \"##\":\n",
        "          continue\n",
        "        try:\n",
        "          tag = line.split('\\t')[3] # 2: pos, 3: ner\n",
        "          if tag in ['B-ORG', 'I-ORG']:\n",
        "            if tag == 'B-ORG':\n",
        "              token = random.sample(org_df['회사명'].tolist(), k=1)[0]\n",
        "            elif tag == 'I-ORG':\n",
        "              token = None\n",
        "            else:\n",
        "              toke = line.split('\\t')[0]\n",
        "          else:\n",
        "            token = line.split('\\t')[0]\n",
        "            tag = 'O'\n",
        "          for i, syllable in enumerate(token): # 음절 단위로 잘라서\n",
        "            tokens.append(syllable)\n",
        "            modi_tag = tag\n",
        "            if i > 0:\n",
        "              if tag[0] == 'B':\n",
        "                modi_tag = 'I' + tag[1:] # BIO tag를 부착\n",
        "            tags.append(modi_tag)\n",
        "        except:\n",
        "          continue\n",
        "      token_docs.append(tokens)\n",
        "      tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n"
      ],
      "metadata": {
        "id": "IeFYumydvif_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, tags = read_file(file_list[:])"
      ],
      "metadata": {
        "id": "pubwPnf3xgY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 데이터셋 준비하기\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "# 3. 모델 학습과정 설정하기\n",
        "# 4. 모델 학습시키기\n",
        "# 5. 모델 학습과정 살펴보기\n",
        "# 6. 모델 평가하기\n",
        "# 7. 모델 사용하기"
      ],
      "metadata": {
        "id": "oyyDQBof27zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])\n",
        "print('전체 리뷰 개수 :',len(total_data)) # 전체 리뷰 개수 출력"
      ],
      "metadata": {
        "id": "U4Z7Jnpg8qfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data[:5]"
      ],
      "metadata": {
        "id": "v-NNgQjT8rL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzSMxp0389fZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}